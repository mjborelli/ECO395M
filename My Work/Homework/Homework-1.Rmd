---
title: "Homework 1"
author: "Matthew Borelli"
date: "2/2/2020"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
```{r ABIA, include=FALSE}
library(tidyverse)
ABIA = read.csv("D:/Documents/MA_Econ/Spring/ECO395M/data/ABIA.csv", header=TRUE)
```

```{r frame, include=FALSE}
daytable = table(ABIA$DayOfWeek,ABIA$Cancelled,ABIA$CancellationCode)
dayframe = as.data.frame(daytable, stringsAsFactors = FALSE)
dayframe = dayframe[c(22:28, 36:42, 50:56),]
colnames(dayframe) = c("Day","Cancelled", "CancellationCode","FlightsCancelled")
days = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
codes = c("Carrier", "Weather", "NAS")
letters = c("A", "B", "C")
dayframe$Day = as.character(dayframe$Day)
for (i in 1 : 7) {
  dayframe$Day[dayframe$Day == i] = days[i]
}
for (k in 1 : 3) {
  dayframe$CancellationCode[dayframe$CancellationCode == letters[k]] = codes[k]
}
dayframe$Day = factor(dayframe$Day,unique(dayframe$Day))
```
With our Austin flight data, I wanted to look at cancellations not just by the day of the week, but also by the listed cause of delay.

```{r ggplot, echo=FALSE}
ggplot(dayframe, mapping = aes(x = Day , y = FlightsCancelled)) +
  geom_bar(mapping = aes(Day, FlightsCancelled), stat = "identity", fill = "dark blue") +
  facet_wrap(~ CancellationCode) +
  theme_grey() +
  theme(axis.text.x=element_text(angle = 90, hjust = 0)) +
  labs(title = "Number of Flight Cancellations by Day of the Week and Cause")
```

There are some clear trends that can be seen in these bar graphs. Carrier cancellations are most common during the week and less common on weekend flights. NAS cancellations are more common on Monday and Tuesday, with the rest of the days being fairly similar. Lastly, weather delays are more common on weekends, but Tuesday seems to be an outlier.

## Question 2

```{r sclass, include=FALSE}
sclass = read.csv("D:/Documents/MA_Econ/Spring/ECO395M/data/sclass.csv")
library(mosaic)
library(FNN)
```

The following is from the code Dr. Scott provided that extracts the 350 and 65 AMG trim levels as subsets of the data.

```{r subset, echo=FALSE}
sclass350 = subset(sclass, trim == '350')

sclass65AMG = subset(sclass, trim == '65 AMG')

# Look at price vs mileage for each trim level
plot(price ~ mileage, data = sclass350)
plot(price ~ mileage, data = sclass65AMG)
```
```{r split, echo=FALSE}
#F irst step is to make the train-test split
N350 = nrow(sclass350)
N_train350 = floor(0.8*N350)
N_test350 = N350 - N_train350

N65 = nrow(sclass65AMG)
N_train65 = floor(0.8*N65)
N_test65 = N65 - N_train65

#Now for each subset, sample the observations into train or test
train350_ind = sample.int(N350, N_train350, replace=FALSE)
train65_ind = sample.int(N65, N_train65, replace=FALSE)

#Data for each group is now separated
D_train350 = sclass350[train350_ind,]
D_test350 = sclass350[-train350_ind,]
D_train65 = sclass65AMG[train65_ind,]
D_test65 = sclass65AMG[-train65_ind,]

D_test350 = arrange(D_test350, mileage)
D_test65 = arrange(D_test65, mileage)
D_train65 = arrange(D_train65, mileage)
D_train350 = arrange(D_train350, mileage)

#now we split the x and y variables apart

X_train350 = select(D_train350, mileage)
y_train350 = select(D_train350, price)
X_test350 = select(D_test350, mileage)
y_test350 = select(D_test350, price)
X_train65 = select(D_train65, mileage)
y_train65 = select(D_train65, price)
X_test65 = select(D_test65, mileage)
y_test65 = select(D_test65, price)

# I get the error "Error in as.matrix(x)[i] : subscript out of bounds"
# when I try to set k = 2, so I will just start at k = 5 unless I can figure something out
knn5_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=5)
knn10_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=10)
knn25_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=25)
knn50_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=50)
knn100_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=100)
knn150_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=150)
knn200_350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=200)


knn5_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=5)
knn10_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=10)
knn25_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=25)
knn50_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=50)
knn100_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=100)
knn150_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=150)
knn200_65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=200)

# create a function for RMSE
rmse = function(y, ypred) {
  sqrt(mean(data.matrix((y-ypred)^2)))
}

# create predictions
ypred_knn5_350 = knn5_350$pred
ypred_knn10_350 = knn10_350$pred
ypred_knn25_350 = knn25_350$pred
ypred_knn50_350 = knn50_350$pred
ypred_knn100_350 = knn100_350$pred
ypred_knn150_350 = knn150_350$pred
ypred_knn200_350 = knn200_350$pred

ypred_knn5_65 = knn5_65$pred
ypred_knn10_65 = knn10_65$pred
ypred_knn25_65 = knn25_65$pred
ypred_knn50_65 = knn50_65$pred
ypred_knn100_65 = knn100_65$pred
ypred_knn150_65 = knn150_65$pred
ypred_knn200_65 = knn200_65$pred

#create RMSE values
rmse_5_350 = rmse(y_test350, ypred_knn5_350)
rmse_10_350 = rmse(y_test350, ypred_knn10_350)
rmse_25_350 = rmse(y_test350, ypred_knn25_350)
rmse_50_350 = rmse(y_test350, ypred_knn50_350)
rmse_100_350 = rmse(y_test350, ypred_knn100_350)
rmse_150_350 = rmse(y_test350, ypred_knn150_350)
rmse_200_350 = rmse(y_test350, ypred_knn200_350)

rmse_5_65 = rmse(y_test65, ypred_knn5_65)
rmse_10_65 = rmse(y_test65, ypred_knn10_65)
rmse_25_65 = rmse(y_test65, ypred_knn25_65)
rmse_50_65 = rmse(y_test65, ypred_knn50_65)
rmse_100_65 = rmse(y_test65, ypred_knn100_65)
rmse_150_65 = rmse(y_test65, ypred_knn150_65)
rmse_200_65 = rmse(y_test65, ypred_knn200_65)
```
The following are the Root Mean-Squared Errors (RMSE) for each of the trim types at specified:
```{r note, include=FALSE}
# I originally wanted to do inline code to display the values, but they would not translate to R correctly.
```
### Trim: 350
- (K = 5) = 10550.83
- (K = 10) = 9749.663
- (K = 25) = 10042.9
- (K = 50) = 10534.91
- (K = 100) = 10534.91
- (K = 150) = 14366.23
- (K = 200) = 16562.14

### Trim: 65 AMG
- (K = 5) = 26064.08
- (K = 10) = 24250.16
- (K = 25) = 23160.28
- (K = 50) = 24296.19
- (K = 100) = 35937.45
- (K = 150) = 53763.28
- (K = 200) = 73465.3

We can look at plots of RMSE versus K to estimate what the optimal K is for each trim.

```{r plots, echo = FALSE}
# For trim 350
KRMSE350 = data.frame(numeric(5), numeric(1))
for (j in 5 : 200) {
  knn350 = knn.reg(train = X_train350, test = X_test350, y = y_train350, k=j)
  ypred_knn350 = knn350$pred
  KRMSE350[j, 1] = rmse(y_test350, ypred_knn350)
  KRMSE350[j, 2] = j
}
```
```{r plyr, include=FALSE}
library(plyr)
```
```{r rename, include=FALSE}
rename(KRMSE350, c("numeric.5." = "RMSE", "numeric.1." = "K"))
```
```{r plots2, echo = FALSE, warning=FALSE}
ggplot(data=KRMSE350, aes(x=KRMSE350[,2], y=KRMSE350[,1])) +
  geom_line(aes(x=KRMSE350[,2], y=KRMSE350[,1]))+
  labs(x = "K", y = "RMSE", title = "K v. RMSE for 350 Trim")+
  xlim(5,200)
```

For the 350 trim, our optimum value of K is K = 50

```{r plots65, include = FALSE}
# For trim 350
KRMSE65 = data.frame(numeric(5), numeric(1))
for (j in 5 : 200) {
  knn65 = knn.reg(train = X_train65, test = X_test65, y = y_train65, k=j)
  ypred_knn65 = knn65$pred
  KRMSE65[j, 1] = rmse(y_test65, ypred_knn65)
  KRMSE65[j, 2] = j
}
```
```{r plyr2, include=FALSE}
library(plyr)
```
```{r rename2, include=FALSE}
rename(KRMSE65, c("numeric.5." = "RMSE", "numeric.1." = "K"))
```
```{r 65plot, echo=FALSE, warning=FALSE}
#getting rid of first four rows (no values)
ggplot(data=KRMSE65, aes(x=KRMSE65[,2], y=KRMSE65[,1])) +
  geom_line(aes(x=KRMSE65[,2], y=KRMSE65[,1]))+
  labs(x = "K", y = "RMSE", title = "K v. RMSE for 65 AMG Trim")+
  xlim(5,200)
```
It is harder to tell for the 65 AMG trim, but it seems that our optimal K is approximately 25.

```{r plot setups, include=FALSE}
knn_model65 = knn.reg(X_train65, X_train65, y_train65, k = 25)
arrange (D_train65, mileage)
D_train65$ypred65 = knn_model65$pred


knn_model350 = knn.reg(X_train350, X_train350, y_train350, k = 50)
arrange (D_train350, mileage)
D_train350$ypred350 = knn_model350$pred
```

```{r plotting, echo=FALSE}
p_train65 = ggplot(data = D_train65) + 
  geom_point(data = D_train65, mapping = aes(x = mileage, y = price), color='grey') + 
  theme_bw(base_size=18) +
  geom_path(data = D_train65, mapping = aes(x=mileage, y = ypred65), color='red', size=1.5) +
  labs(title = "Predictions for 65 AMG Trim")
p_train65

p_train350 = ggplot(data = D_train350) + 
  geom_point(data = D_train350, mapping = aes(x = mileage, y = price), color='grey') + 
  theme_bw(base_size=18) +
  geom_path(data = D_train350, mapping = aes(x=mileage, y = ypred350), color='red', size=1.5) +
  labs(title = "Predictions for 350 Trim")
p_train350
```

Of the two trims, the 350 trim has a higher optimal K than the 65 AMG trim. This has nothing to do with the difference in the trims. The main reason for the difference is that the subset of S-Class cars with 350 trim is larger than the subset with 65 AMG trim. When you have more data, the optimal value for K increases because your points will be closer together and therefore create better predictions.
